{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJECT DESCRIPTION\n",
    "\n",
    "Motor vehicles continuously collect data on driver input parameters, including brake pressure, steering angle, accelerator pedal position, and more. This data is stored in a vehicle’s Airbag Control Module and can be retrieved after the crash. A tool will be created to ingest and prepare this data for preliminary analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION (Deliverables).\n",
    "\n",
    "•\tAutomate process to open proprietary format in Bosch software and export as CSV.\n",
    "\n",
    "•\tFollow Data Engineering Lifecycle to ingest, anonymize, and store data.\n",
    "\n",
    "•\tHomogenize the dataset so that it can be studied effectively.\n",
    "\n",
    "•\tContinuously discover and ingest data.\n",
    "\n",
    "•\tPerform Experimental Data Analysis with an unfamiliar tool (SpeedML)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASETS: Corporate pre-crash records in semistructured NTFS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN OF ACTION\n",
    "\n",
    "1) Ingestion\n",
    "\n",
    "    a) Develop a list of filenames and their respective directories, \n",
    "        so that pyAutoGUI can open the files with Bosch CDR\n",
    "\n",
    "    b) Use pyautoGUI to launch each file individually and save a CSV to that same folder.\n",
    "\n",
    "    c) Create code to scrape each CSV into Pandas, either a dedicated dataframe or a master DF so that info can be extracted.\n",
    "\n",
    "    d) Develop a system for re-scanning the database, identifying new files, and then importing only those.\n",
    "    \n",
    "2) Cleaning of data and Exploratory Data Analysis (EDA)\n",
    "\n",
    "    Two things must be accomplished here:\n",
    "    \n",
    "    a) First, we should preserve the granularity of data by importing all crash information.\n",
    "    \n",
    "    b) Next, we should identify elements common to all records so that we can leverage the entire dataset for study.\n",
    "\n",
    "    This is a place where SpeedML may be useful. We don't have to fully clean the data before doing some exploration.\n",
    "\n",
    "    c) Preliminary EDA will be necessary to determine how to structure the schema. This can be accomplished in Jupyter.\n",
    "\n",
    "    d) Identify how to break elements out into a dataframe so that the scientists can have 'all the data.'\n",
    "\n",
    "3) Future Work\n",
    "\n",
    "    a) Package the project as an executable using PyOxidizer so that any person or process can leverage it to scrape data and feed it to the pipeline.\n",
    "\n",
    "    b) Learn how to best manage new vehicles, data, and formats being added to the fleet. This will be accomplished through either complete liberation of the code from the data format (i.e. use RegEx for everything) or a graphical interface for identifying key data and 'training' the code.\n",
    "\n",
    "    c) Integrate new data sources such as proprietary insurance databases, news, and email.\n",
    "\n",
    "    d) Add utility for users who feed data into the system so that it is regularly maintained and used. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
