{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_dataframe = pd.read_pickle('working_files/records_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes the Pre-Crash data string and converts it to table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = records_dataframe['Pre-Crash Data'].iloc[1]\n",
    "\n",
    "# create a list of rows from the data\n",
    "rows = data.split('\\n')\n",
    "\n",
    "event_1_pre_crash_data = []\n",
    "for i in range(1, len(rows)):\n",
    "    # use strip() to remove any extra white space or line breaks from the row\n",
    "    row = rows[i].strip()\n",
    "    if not row:\n",
    "        # skip empty rows\n",
    "        continue\n",
    "    event_1_pre_crash_data.append(next(csv.reader([row])))\n",
    "\n",
    "analysis_table_dataframe = pd.DataFrame(event_1_pre_crash_data, columns=event_1_pre_crash_data[0])\n",
    "analysis_table_dataframe = analysis_table_dataframe.iloc[1:].reset_index(drop=True)\n",
    "analysis_table_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the DataFrame index to avoid errors during iteration and remove empty rows that don't contain records\n",
    "records_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(records_dataframe)):\n",
    "    # get the Pre-Crash Data for the current row\n",
    "    data = records_dataframe['Pre-Crash Data'].iloc[i]\n",
    "\n",
    "    # check if the data is a string to prevent string errors\n",
    "    if not isinstance(data, str):\n",
    "        # if not, set the value to NaN and skip to the next iteration\n",
    "        continue\n",
    "\n",
    "    # create a list of rows from the data\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    event_1_pre_crash_data = []\n",
    "    for j in range(1, len(rows)):\n",
    "        try:\n",
    "            # use a try/except block to catch any errors\n",
    "            event_1_pre_crash_data.append(next(csv.reader([rows[j]])))\n",
    "        except csv.Error:\n",
    "            # if an error occurs, skip to the next iteration\n",
    "            continue\n",
    "\n",
    "    analysis_table_dataframe['Pre-Crash Dataframe'] = pd.DataFrame(event_1_pre_crash_data, columns=event_1_pre_crash_data[0])\n",
    "\n",
    "    # save the DataFrame to a new variable\n",
    "    # vin = records_dataframe['VIN'].iloc[i]\n",
    "    # pd.to_pickle(analysis_table_dataframe, f'{vin}_first_record_pre_crash_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the DataFrame index to avoid errors during iteration and remove empty rows that don't contain records\n",
    "records_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# initialize an empty dataframe for each unique VIN\n",
    "unique_vins = records_dataframe['VIN'].unique()\n",
    "pre_crash_dataframes = {vin: pd.DataFrame() for vin in unique_vins}\n",
    "\n",
    "for i in range(len(records_dataframe)):\n",
    "    # get the Pre-Crash Data for the current row\n",
    "    data = records_dataframe['Pre-Crash Data'].iloc[i]\n",
    "\n",
    "    # check if the data is a string to prevent string errors\n",
    "    if not isinstance(data, str):\n",
    "        # if not, set the value to NaN and skip to the next iteration\n",
    "        continue\n",
    "\n",
    "    # create a list of rows from the data\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    event_1_pre_crash_data = []\n",
    "    for j in range(1, len(rows)):\n",
    "        try:\n",
    "            # use a try/except block to catch any errors\n",
    "            event_1_pre_crash_data.append(next(csv.reader([rows[j]])))\n",
    "        except csv.Error:\n",
    "            # if an error occurs, skip to the next iteration\n",
    "            continue\n",
    "\n",
    "    # save the DataFrame to the pre_crash_dataframes dictionary with the corresponding VIN as the key\n",
    "    vin = records_dataframe['VIN'].iloc[i]\n",
    "    pre_crash_dataframes[vin] = pd.DataFrame(event_1_pre_crash_data[1:], columns=event_1_pre_crash_data[0]).dropna()\n",
    "\n",
    "# add the DataFrame dictionary to the records_dataframe\n",
    "records_dataframe['Pre-Crash Dataframes'] = [pre_crash_dataframes[vin] if vin in pre_crash_dataframes else pd.DataFrame() for vin in records_dataframe['VIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_dataframe['Pre-Crash Dataframes'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(records_dataframe, 'working_files/records_dataframe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
