{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataframe = pd.read_csv('master_dataframe.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, design the schema. Identify each piece of information in the schema manually and add it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Complete Record\n",
      "0                                 CDR FILE INFORMATION\n",
      "1                   User Entered VIN,1FDXE4FSXCDA06364\n",
      "2                                              User,SP\n",
      "3                              Case Number,866715-2017\n",
      "4    EDR Data Imaging Date,\"08/07/2017             ...\n",
      "..                                                 ...\n",
      "326                                210.0,-10.10,-16.26\n",
      "327                                220.0,-10.14,-16.31\n",
      "328                                 230.0,-9.96,-16.03\n",
      "329                                 240.0,-9.49,-15.27\n",
      "330                                 250.0,-9.20,-14.80\n",
      "\n",
      "[331 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "row_index = [4]\n",
    "complete_record_value = master_dataframe.loc[row_index, 'Complete Records']\n",
    "complete_record_value_df = complete_record_value.iloc[0]\n",
    "\n",
    "print(complete_record_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'..\\final_project\\test_cdr_directory\\1FDXE4FSXCDA06364_ACM\\1FDXE4FSXCDA06364_ACM.CSV'\n",
    "with open(test_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "file_encoding = result['encoding']\n",
    "print(file_encoding)\n",
    "df = pd.read_csv(test_path, encoding = file_encoding, delimiter = '\\r\\n', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "test_path = r'..\\final_project\\test_cdr_directory\\1FDXE4FSXCDA06364_ACM\\1FDXE4FSXCDA06364_ACM.CSV'\n",
    "with open(test_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "file_encoding = result['encoding']\n",
    "print(file_encoding)\n",
    "\n",
    "# read in the CSV file and split each row by comma\n",
    "df = pd.read_csv(test_path, encoding=file_encoding, delimiter='\\r\\n', engine='python')\n",
    "#Turning this block into a loop allows exception handling for integers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to extract via CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_tables(input_file, output_file):\n",
    "    # Define the table headers and their corresponding row indices\n",
    "    headers = {\n",
    "        \"pre_crash_2_sec_2_samples\": {\"pattern\": r\"PRE-CRASH DATA -2 SEC \\[2 SAMPLES/SEC\\] \\(FIRST RECORD\\)\", \"row_offset\": 1},\n",
    "        \"pre_crash_5_to_0_sec_2_samples\": {\"pattern\": r\"PRE-CRASH DATA -5 TO 0 SEC \\[2 SAMPLES/SEC\\] \\(FIRST RECORD\\)\", \"row_offset\": 1},\n",
    "        \"pre_crash_5_to_0_sec_10_samples\": {\"pattern\": r\"PRE-CRASH DATA -5 TO 0 SEC \\[10 SAMPLES/SEC\\] \\(FIRST RECORD\\)\", \"row_offset\": 1},\n",
    "        \"longitudinal_crash_pulse\": {\"pattern\": r\"LONGITUDINAL CRASH PULSE \\(FIRST RECORD\\)\", \"row_offset\": 1},\n",
    "        \"lateral_crash_pulse\": {\"pattern\": r\"LATERAL CRASH PULSE \\(FIRST RECORD\\)\", \"row_offset\": 1}\n",
    "    }\n",
    "    \n",
    "    # Open the input and output files\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\", newline=\"\") as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        # Find the table headers and their starting row indices\n",
    "        table_starts = {}\n",
    "        for i, row in enumerate(reader):\n",
    "            for header, metadata in headers.items():\n",
    "                if re.search(metadata[\"pattern\"], row[0], re.IGNORECASE):\n",
    "                    table_starts[header] = i + metadata[\"row_offset\"]\n",
    "        \n",
    "        # Extract the tables and write them to the output file\n",
    "        for header, start_row in table_starts.items():\n",
    "            writer.writerow([header])\n",
    "            for row in reader:\n",
    "                if len(row) == 0:\n",
    "                    break\n",
    "                elif row[0].startswith(\"Refer to the CDR report for data limitations\"):\n",
    "                    break\n",
    "                elif len(row) > 1 and row[1] == \"\":\n",
    "                    break\n",
    "                elif reader.line_num < start_row:\n",
    "                    continue\n",
    "                elif reader.line_num == start_row:\n",
    "                    writer.writerow(row)\n",
    "                else:\n",
    "                    writer.writerow(row[:-1])\n",
    "            writer.writerow([])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
