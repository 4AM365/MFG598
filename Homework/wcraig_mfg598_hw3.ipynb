{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest 5 non-zero scores and their associated values are: \n",
      " [('103', 56), ('109', 66), ('106', 75), ('104', 78), ('113', 86)]\n"
     ]
    }
   ],
   "source": [
    "# Qn 1 (10 points)\n",
    "# Read the file ‘grades.csv’. Write code that finds and displays the 5 student IDs \n",
    "# and their corresponding grades who received the lowest grades in the class. \n",
    "# Some students have not appeared for the exam, but they are not to be treated as 0. \n",
    "# They need to be simply skipped from the computation. (20points)\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import csv\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\\\Code\\\\MFG598\\\\Homework\\\\Resources\\\\HW3_Data_Files.zip\", \"r\") as unzipped_file:\n",
    "    unzipped_file.extractall()\n",
    "\n",
    "with open(\"grades.csv\", \"r\") as csv_file:\n",
    "    csv_contents = csv.DictReader(csv_file)\n",
    "    nonzero_dict = {}\n",
    "\n",
    "    for row in csv_contents:\n",
    "        if row[\"Scores\"]:\n",
    "            nonzero_dict[row['Student IDs']] = int(row['Scores'])\n",
    "\n",
    "    sorted_nonzero_dict = dict(sorted(nonzero_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "    sorted_nonzero_dict_lowest_five = list(sorted_nonzero_dict.items())[:5]\n",
    "\n",
    "    print(f\"The lowest 5 non-zero scores and their associated values are: \\n {sorted_nonzero_dict_lowest_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-16\n",
      "There are 1340 lines in the file, excluding the header\n",
      "The sum of all integer values in the .txt file is 161509\n",
      "The part ID with the highest # of associated parts is 122f3850-6378-489c-ae21-b88c035c2818\n",
      "The number of associated parts for that ID is 99\n"
     ]
    }
   ],
   "source": [
    "# Qn 2 (20 points)\n",
    "# Open and read the contents of the file – ‘2_NoofParts_assem.txt’. Perform the following (20 points):\n",
    "# a)\tCalculate how many entries are available in that file excluding the header.\n",
    "# b)\tCalculate the sum of all parts from each file. Essentially, finding the sum of all values contained in the 2nd column of the file.\n",
    "# c)\tExtract the part ID that has the largest associated no. of parts from the entire list_input.\n",
    "\n",
    "\n",
    "file = \"2_NoofParts_assem.txt\"\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", 'r') as unzipped:\n",
    "    unzipped.extractall()\n",
    "\n",
    "#When I try to open here, I get a decode error for utf-8. What type of encoding is this file?\n",
    "\n",
    "#\"rb\" does \"read binary\" so we can look deeply in the file.\n",
    "with open(\"2_NoofParts_assem.txt\", \"rb\") as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    print(result['encoding'])\n",
    "\n",
    "#Not sure how to integrate this into the encoding = statement below. I'm sure there's a way.\n",
    "\n",
    "with open(\"2_NoofParts_assem.txt\", 'r', encoding = 'utf-16') as file:\n",
    "    #print(file.read())\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "\n",
    "print(f'There are {num_lines - 1} lines in the file, excluding the header')\n",
    "\n",
    "#Doing my EDA here\n",
    "#print(lines) \n",
    "#Based on this print statement, our values are separated by \\t and followed by \\t\\t\\n\n",
    "#There's a value to 'clean' the statement but I don't remember right now.\n",
    "\n",
    "#Let's first split the items.\n",
    "\n",
    "split_values = []\n",
    "for item in lines:\n",
    "    split_values.append(item.split(\"\\t\"))\n",
    "\n",
    "#print(split_values)\n",
    "\n",
    "#From this print statement, we see that the header is still included. We can take it out now or later, because it will interfere with int operations.\n",
    "#We can nest the entire value-stripping code block in a 'try' statement and then exit if we have a ValueError.\n",
    "#We also need to account for the fact that the list_input now consists of lists.\n",
    "\n",
    "values_only = []\n",
    "for sublist in split_values:\n",
    "    for item in sublist:\n",
    "        try:\n",
    "            values_only.append(int(item))\n",
    "        except ValueError:\n",
    "            continue\n",
    "#print(values_only)\n",
    "\n",
    "print(f\"The sum of all integer values in the .txt file is {sum(values_only)}\")\n",
    "\n",
    "# c)\tExtract the part ID that has the largest associated no. of parts from the entire list_input.\n",
    "\n",
    "#We need to know which entry in the list_input of lists has the max value, then we can just navigate to it.\n",
    "#My instinct is to iterate through the list_input increasing an index number, but I feel like there's a more elegant way.\n",
    "#I learned about custom keys and will apply that here.\n",
    "\n",
    "#This definition gives us the key value of whatever term in the master list_input that we want.\n",
    "def extract_max_num(item):\n",
    "    return (item[1])\n",
    "\n",
    "#This item finds the sublist. The value in the brackets lets us 'skip' the header, starting at 1 and going onward.\n",
    "max_part = max(split_values[1:], key=extract_max_num)\n",
    "\n",
    "#The definition acts like a lambda function in that the value of max() is used as a parameter.\n",
    "\n",
    "part_id = max_part[0]\n",
    "\n",
    "print(f\"The part ID with the highest # of associated parts is {part_id}\")\n",
    "print(f\"The number of associated parts for that ID is {max_part[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs completed: 2384\n"
     ]
    }
   ],
   "source": [
    "# Qn 3 (25 points)\n",
    "# Using a python script, open the files contained in the .zip file – “3_Jobs_Completed_log.zip”. \n",
    "# Scan the files for the line that starts with the word string – “Jobs Completed.. ”. Extract the number associated with this line and for all instances that this word string appears across all log files, count the total sum across all files contained within the .zip file. (20points) \n",
    "\n",
    "# For example:\n",
    "\n",
    "#  \tJobs Completed.. 10 2018-09-04 08:21:28.503153\n",
    "\n",
    "# Extract the number 10 from this sentence which signifies the total number of jobs completed at the point in time.  \n",
    "# Find for all instances in which the string - ‘Jobs Completed’ appears, \n",
    "# find the total number of jobs completed by adding the numbers from across the provided log files.\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "\n",
    "filetypes = []\n",
    "total_sum = 0\n",
    "#Opening .zip within .zip here and extracting:\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", 'r') as wrapper:\n",
    "    with wrapper.open(\"Jobs_Completed_log.zip\", 'r') as Jobs_Completed_file:\n",
    "            with zipfile.ZipFile(Jobs_Completed_file) as Jobs_Completed_log:\n",
    "\n",
    "#Next I'll iterate through a list_input of the files and detect encoding for each with chardet, since I have no idea if they are homoegenous.\n",
    "#Is this overkill?\n",
    "#To make the code resilient, I'll pass the encoding data to another \n",
    "\n",
    "                #I was doing this by habit, but it looks like it's not necessary if I work within the zipfile condition. \n",
    "                #   Not sure if this is preferable.\n",
    "                # Jobs_Completed_log.extractall()\n",
    "\n",
    "                Jobs_Completed_log_file_list = Jobs_Completed_log.namelist()\n",
    "                for file in Jobs_Completed_log_file_list[:len(Jobs_Completed_log_file_list)]:\n",
    "                    with Jobs_Completed_log.open(file) as f:\n",
    "                        file_data = f.read()\n",
    "                        encoding_result = chardet.detect(file_data)\n",
    "                        encoding = encoding_result[\"encoding\"]\n",
    "                        filetypes.append(encoding)\n",
    "\n",
    "                        #Found that a typical str.split does not work here like splitting a utf-8 file does.\n",
    "                            # Resulted in a TypeError \n",
    "                            # Instead, I'll 'decode'.\n",
    "                        file_data_str = file_data.decode(encoding)\n",
    "                        lines = file_data_str.split(\"\\n\")\n",
    "\n",
    "                        #Now that we have useful data, I'll search for the Jobs Completed lines, \n",
    "                        #   split then up, and grab the total number with an index.\n",
    "                        for line in lines:\n",
    "                            if line.startswith(\"Jobs Completed.. \"):\n",
    "                                parts = line.split(\" \")\n",
    "                                total_sum += int(parts[2])\n",
    "\n",
    "#print(\"Filetypes:\", filetypes)\n",
    "print(\"Jobs completed:\", total_sum)\n",
    "#print(file_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qn 4 (20 points)\n",
    "# For the same files above, calculate the following:\n",
    "# a)\tHow many jobs were completed in the period between 15th Aug 2018 to 15th Sept 2018?\n",
    "# b)\tThe day of the year in which the maximum number of jobs was completed.\n",
    "# c)\tCalculate the total number of days elapsed between the time at which the first job batch was completed to the last batch completed.\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "#Rewriting this part to help me remember it.\n",
    "filetypes = []\n",
    "encoding = []\n",
    "date_list = []\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", \"r\") as unzipped_outer:\n",
    "    with unzipped_outer.open(\"Jobs_Completed_log.zip\", \"r\") as inner_container:\n",
    "        with zipfile.ZipFile(inner_container, \"r\") as unzipped_inner:\n",
    "\n",
    "            file_list = unzipped_inner.namelist()\n",
    "            for file in file_list[:len(file_list)]:\n",
    "                with unzipped_inner.open(file) as f:\n",
    "                    file_data = f.read()\n",
    "                    #print(file_data)\n",
    "                    encoding_result = chardet.detect(file_data)\n",
    "                    encoding = encoding_result[\"encoding\"]\n",
    "                    #print(encoding)\n",
    "                    filetypes.append(encoding)\n",
    "\n",
    "#I got a bit distracted with this common_encoding block. I was trying to figure out how to make the code filetype agnostic. \n",
    "#Upon reflection, I may have been able to nest chardet.detect as such: file_data.decode(chardet.detect(file_data))\n",
    "\n",
    "def common_encoding(list_input):\n",
    "    if all(x == list_input[0] for x in list_input):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "while True:\n",
    "    if common_encoding(filetypes):\n",
    "        date_list.append(re.findall(r'\\b\\d{4}-\\d{2}-\\d{2}', file_data.decode(filetypes[0])))       \n",
    "        break\n",
    "\n",
    "\n",
    "# define start and end date of the range\n",
    "start_date = datetime(2018, 8, 15)\n",
    "\n",
    "end_date = datetime(2018, 9, 15)\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", \"r\") as unzipped_outer:\n",
    "    with unzipped_outer.open(\"Jobs_Completed_log.zip\", \"r\") as inner_container:\n",
    "        with zipfile.ZipFile(inner_container, \"r\") as unzipped_inner:\n",
    "        # Loop over the 5 text files inside the inner .zip file\n",
    "            for filename in unzipped_inner.namelist():\n",
    "                if filename.endswith('.txt'):\n",
    "                    # Read the text file\n",
    "                    with unzipped_inner.open(filename) as txt_file:\n",
    "                        txt_data = txt_file.read()\n",
    "                        \n",
    "                        data_split = txt_data.split(b'Date:')\n",
    "                        if len(data_split) > 1:\n",
    "                            date_str = data_split[1].strip()\n",
    "\n",
    "                            date_list.append(date_str)                        \n",
    "                        # Add the parsed date to the list of parsed dates\n",
    "#print(date_list)\n",
    "\n",
    "parsed_dates = [datetime.strptime(date, '%Y-%m-%d') for date in str(date_list)]\n",
    "\n",
    "count = 0\n",
    "for date in parsed_dates:\n",
    "    if start_date <= date <= end_date:\n",
    "        count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of triangles is: 44\n",
      "Total area of all triangles is: 1022629.4450895642. \n",
      " The areas of each triangle in the mesh follow:\n",
      "[0.0, 0.0, 0.0, 2638.9353534853403, 5472.944843684953, 13085.550675119106, 9744.057557894803, 0.0, 106497.19095809023, 15631.535308557655, 145880.1784239923, 145880.1784239923, 106497.19095809023, 9459.949236665683, 9459.949236665685, 28294.53112314489, 3692.9550878294663, 28294.5311231449, 26323.460256115435, 3692.9550878294663, 45158.04214259463, 45158.04214259464, 26323.460256115435, 5472.944843684953, 5472.944843684953, 2638.9353534853403, 0.0, 9933.88744898081, 2638.9353534853412, 0.0, 6537.786042777389, 9933.887448980808, 7099.877958781198, 7099.877958781198, 3566.0235234441257, 13167.256416249083, 33228.97134803277, 11531.591827811746, 28377.47583342216, 27533.410225028416, 15783.804821429241, 11188.593735626715, 14246.033970931187, 29991.567939339788]\n"
     ]
    }
   ],
   "source": [
    "# Qn 5 (25 points)\n",
    "# Read the following (6_Part1.stl) triangular mesh file available in ASCII format. \n",
    "# For those of you aware of 3D printing, you will recognize this is as a .STL file. \n",
    "# For those who aren’t aware of what a .STL file is, please read up online on the format of a .STL ascii file. \n",
    "# An ASCII formatted .STL file can be opened in any text editor. \n",
    "# Every vertex of the triangle is preceeded by the word ‘vertex’ followed by the x, y and z coordinates. \n",
    "# Therefore, ONE Triangle should have 3 vertex entries. Typically, the units is not specified, \n",
    "# but you can assume it to be in millimeters. \n",
    "\n",
    "# Write functions that calculate the following: (20 points)\n",
    "# a.\tFind the total number of triangles listed in the file.\n",
    "# b.\tStore the coordinates of each triangle in a 3-tuple list_input containing N indices, where N is the total number of triangles.\n",
    "# c.\tlist_input the area of each triangle in the file. Compute the total surface area of all triangles listed in the file. Read up online on the formula to calculate the area of a triangle, given three vertices.\n",
    "# '''\n",
    "\n",
    "file = \"C:/Code/MFG598/Homework/6_Part1.stl\"\n",
    "vertex_count = 0\n",
    "\n",
    "#Using the counting function is going to be more lightweight than using file.readlines()\n",
    "    #...then iterating through the list of lines. We'll readlines later however.\n",
    "with open(file, \"r\") as stl_file:\n",
    "    file_data = stl_file.read()\n",
    "    vertex_count = file_data.count(\"vertex\")\n",
    "\n",
    "triangle_count = vertex_count/3\n",
    "\n",
    "print(f\"The number of triangles is: {int(triangle_count)}\")\n",
    "\n",
    "#Now we're using readlines and we'll use 'vertex' as a pointer to access just the tuple of values after it.\n",
    "with open(file, \"r\") as file:\n",
    "    file_data = file.readlines()\n",
    "\n",
    "triangles = []\n",
    "for line in file_data:\n",
    "    if 'vertex' in line:\n",
    "        coordinates = tuple([float(x) for x in line.strip().split()[1:]])\n",
    "        triangles.append(coordinates)\n",
    "\n",
    "#Now find the total area of all triangles, and also the area of each triangle.\n",
    "#I'm not sure if the question wants me to append this to list_input\n",
    "\n",
    "area_list = []\n",
    "\n",
    "\n",
    "tri = [triangles[i:i+3] for i in range(0, len(triangles), 3)]\n",
    "\n",
    "#Going to assume that the triangle format is Ax, Ay, Az, Bx, By, Bz...\n",
    "#Iterate through each grouping of vertices and then do the math for volume.\n",
    "def triangle_volume(tri):\n",
    "    x1, y1, z1 = tri[0]\n",
    "    x2, y2, z2 = tri[1]\n",
    "    x3, y3, z3 = tri[2]\n",
    "    return abs(x1*y2*z3 + x2*y3*z1 + x3*y1*z2 - x1*y3*z2 - x2*y1*z3 - x3*y2*z1) / 6\n",
    "\n",
    "volumes = [triangle_volume(triangle) for triangle in tri]\n",
    "print(f\"Total area of all triangles is: {sum(volumes)}. \\n The areas of each triangle in the mesh follow:\")\n",
    "print(volumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
