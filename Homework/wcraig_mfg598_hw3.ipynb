{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#William Craig\n",
    "#MFG 598\n",
    "#HW3\n",
    "#February 8, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest 5 non-zero scores and their associated values are: \n",
      " [('103', 56), ('109', 66), ('106', 75), ('104', 78), ('113', 86)]\n"
     ]
    }
   ],
   "source": [
    "# Qn 1 (10 points)\n",
    "# Read the file ‘grades.csv’. Write code that finds and displays the 5 student IDs \n",
    "# and their corresponding grades who received the lowest grades in the class. \n",
    "# Some students have not appeared for the exam, but they are not to be treated as 0. \n",
    "# They need to be simply skipped from the computation. (20points)\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import csv\n",
    "\n",
    "#This code extracts the contents of a zipped file into a working directory.\n",
    "\n",
    "#An alternative is to work within the zipped file, but this code is also easier to understand.\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\\\Code\\\\MFG598\\\\Homework\\\\Resources\\\\HW3_Data_Files.zip\", \"r\") as unzipped_file:\n",
    "    unzipped_file.extractall()\n",
    "\n",
    "#This simply opens a csv from the working directory.\n",
    "\n",
    "with open(\"grades.csv\", \"r\") as csv_file:\n",
    "    #Extracts contents of the file in the format of a dictionary. \n",
    "    csv_contents = csv.DictReader(csv_file)\n",
    "    nonzero_dict = {}\n",
    "\n",
    "#This code iterates through the contents of a the new dictionary and appends them to a dictionary if the score is nonzero. \n",
    "#   This is accomplished by 'if row[\"Scores\"]:\", where it is implied that the 'True' result entails a value existing. \n",
    "    for row in csv_contents:\n",
    "        if row[\"Scores\"]:\n",
    "            #This opportunity is taken to turn scores into integers, so that they can be sorted later. Strings can be sorted as well, but this is more intuitive.\n",
    "            nonzero_dict[row['Student IDs']] = int(row['Scores'])\n",
    "\n",
    "#Sorting is difficult with libraries, since they are by definition unordered.\n",
    "#Here, we essentially convert the scores column into a list, associate each value with a key using lambda, then place the contents back into a new dictionary in sequence.\n",
    "    sorted_nonzero_dict = dict(sorted(nonzero_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "#Again, we cannot print the highest or lowest values of a dictionary. Therefore, we print the first five values of a sorted list.\n",
    "    sorted_nonzero_dict_lowest_five = list(sorted_nonzero_dict.items())[:5]\n",
    "\n",
    "    print(f\"The lowest 5 non-zero scores and their associated values are: \\n {sorted_nonzero_dict_lowest_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qn 2 (20 points)\n",
    "# Open and read the contents of the file – ‘2_NoofParts_assem.txt’. Perform the following (20 points):\n",
    "# a)\tCalculate how many entries are available in that file excluding the header.\n",
    "# b)\tCalculate the sum of all parts from each file. Essentially, finding the sum of all values contained in the 2nd column of the file.\n",
    "# c)\tExtract the part ID that has the largest associated no. of parts from the entire list_input.\n",
    "\n",
    "\n",
    "file = \"2_NoofParts_assem.txt\"\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", 'r') as unzipped:\n",
    "    unzipped.extractall()\n",
    "\n",
    "#When I try to open here, I get a decode error for utf-8. What type of encoding is this file?\n",
    "\n",
    "#\"rb\" does \"read binary\" so we can look deeply in the file.\n",
    "with open(\"2_NoofParts_assem.txt\", \"rb\") as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    print(result['encoding'])\n",
    "\n",
    "#Not sure how to integrate this into the encoding = statement below. I'm sure there's a way.\n",
    "\n",
    "with open(\"2_NoofParts_assem.txt\", 'r', encoding = 'utf-16') as file:\n",
    "    #print(file.read())\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "\n",
    "print(f'There are {num_lines - 1} lines in the file, excluding the header')\n",
    "\n",
    "#Doing my EDA here\n",
    "#print(lines) \n",
    "#Based on this print statement, our values are separated by \\t and followed by \\t\\t\\n\n",
    "#There's a value to 'clean' the statement but I don't remember right now.\n",
    "\n",
    "#Let's first split the items.\n",
    "\n",
    "split_values = []\n",
    "for item in lines:\n",
    "    split_values.append(item.split(\"\\t\"))\n",
    "\n",
    "#print(split_values)\n",
    "\n",
    "#From this print statement, we see that the header is still included. We can take it out now or later, because it will interfere with int operations.\n",
    "#We can nest the entire value-stripping code block in a 'try' statement and then exit if we have a ValueError.\n",
    "#We also need to account for the fact that the list_input now consists of lists.\n",
    "\n",
    "values_only = []\n",
    "for sublist in split_values:\n",
    "    for item in sublist:\n",
    "        try:\n",
    "            values_only.append(int(item))\n",
    "        except ValueError:\n",
    "            continue\n",
    "#print(values_only)\n",
    "\n",
    "print(f\"The sum of all integer values in the .txt file is {sum(values_only)}\")\n",
    "\n",
    "# c)\tExtract the part ID that has the largest associated no. of parts from the entire list_input.\n",
    "\n",
    "#We need to know which entry in the list_input of lists has the max value, then we can just navigate to it.\n",
    "#My instinct is to iterate through the list_input increasing an index number, but I feel like there's a more elegant way.\n",
    "#I learned about custom keys and will apply that here.\n",
    "\n",
    "#This definition gives us the key value of whatever term in the master list_input that we want.\n",
    "def extract_max_num(item):\n",
    "    return (item[1])\n",
    "\n",
    "#This item finds the sublist. The value in the brackets lets us 'skip' the header, starting at 1 and going onward.\n",
    "max_part = max(split_values[1:], key=extract_max_num)\n",
    "\n",
    "#The definition acts like a lambda function in that the value of max() is used as a parameter.\n",
    "\n",
    "part_id = max_part[0]\n",
    "\n",
    "print(f\"The part ID with the highest # of associated parts is {part_id}\")\n",
    "print(f\"The number of associated parts for that ID is {max_part[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qn 3 (25 points)\n",
    "# Using a python script, open the files contained in the .zip file – “3_Jobs_Completed_log.zip”. \n",
    "# Scan the files for the line that starts with the word string – “Jobs Completed.. ”. Extract the number associated with this line and for all instances that this word string appears across all log files, count the total sum across all files contained within the .zip file. (20points) \n",
    "\n",
    "# For example:\n",
    "\n",
    "#  \tJobs Completed.. 10 2018-09-04 08:21:28.503153\n",
    "\n",
    "# Extract the number 10 from this sentence which signifies the total number of jobs completed at the point in time.  \n",
    "# Find for all instances in which the string - ‘Jobs Completed’ appears, \n",
    "# find the total number of jobs completed by adding the numbers from across the provided log files.\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "\n",
    "filetypes = []\n",
    "total_sum = 0\n",
    "#Opening .zip within .zip here and extracting:\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", 'r') as wrapper:\n",
    "    with wrapper.open(\"Jobs_Completed_log.zip\", 'r') as Jobs_Completed_file:\n",
    "            with zipfile.ZipFile(Jobs_Completed_file) as Jobs_Completed_log:\n",
    "\n",
    "#Next I'll iterate through a list_input of the files and detect encoding for each with chardet, since I have no idea if they are homoegenous.\n",
    "#Is this overkill?\n",
    "#To make the code resilient, I'll pass the encoding data to another \n",
    "\n",
    "                #I was doing this by habit, but it looks like it's not necessary if I work within the zipfile condition. \n",
    "                #   Not sure if this is preferable.\n",
    "                # Jobs_Completed_log.extractall()\n",
    "\n",
    "                Jobs_Completed_log_file_list = Jobs_Completed_log.namelist()\n",
    "                for file in Jobs_Completed_log_file_list[:len(Jobs_Completed_log_file_list)]:\n",
    "                    with Jobs_Completed_log.open(file) as f:\n",
    "                        file_data = f.read()\n",
    "                        encoding_result = chardet.detect(file_data)\n",
    "                        encoding = encoding_result[\"encoding\"]\n",
    "                        filetypes.append(encoding)\n",
    "\n",
    "                        #Found that a typical str.split does not work here like splitting a utf-8 file does.\n",
    "                            # Resulted in a TypeError \n",
    "                            # Instead, I'll 'decode'.\n",
    "                        file_data_str = file_data.decode(encoding)\n",
    "                        lines = file_data_str.split(\"\\n\")\n",
    "\n",
    "                        #Now that we have useful data, I'll search for the Jobs Completed lines, \n",
    "                        #   split then up, and grab the total number with an index.\n",
    "                        for line in lines:\n",
    "                            if line.startswith(\"Jobs Completed.. \"):\n",
    "                                parts = line.split(\" \")\n",
    "                                total_sum += int(parts[2])\n",
    "\n",
    "#print(\"Filetypes:\", filetypes)\n",
    "print(\"Jobs completed:\", total_sum)\n",
    "#print(file_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries between 2018-08-15 and 2018-09-15 is 2004\n",
      "The day with the most associated jobs is: 2018-08-11\n",
      "The days elapsed between the first job and last job are 36 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Qn 4 (20 points)\n",
    "# For the same files above, calculate the following:\n",
    "# a)\tHow many jobs were completed in the period between 15th Aug 2018 to 15th Sept 2018?\n",
    "# b)\tThe day of the year in which the maximum number of jobs was completed.\n",
    "# c)\tCalculate the total number of days elapsed between the time at which the first job batch was completed to the last batch completed.\n",
    "\n",
    "import zipfile\n",
    "import chardet\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import statistics\n",
    "\n",
    "filetypes = []\n",
    "total_sum = 0\n",
    "master_file = []\n",
    "date_list = []\n",
    "\n",
    "date_format = '\\b\\n{4}-'\n",
    "\n",
    "# Opening .zip within .zip here and extracting:\n",
    "with zipfile.ZipFile(\"C:\\Code\\MFG598\\Homework\\Resources\\HW3_Data_Files.zip\", 'r') as wrapper:\n",
    "    inner_zip = wrapper.open(\"Jobs_Completed_log.zip\")\n",
    "    with zipfile.ZipFile(inner_zip) as Jobs_Completed_file:\n",
    "        #The code iterates through each file by creating a list of names and then selecting them one-by-one.\n",
    "        for filename in Jobs_Completed_file.namelist():\n",
    "            #For each file, it is opened as 'file' then an operation is performed.\n",
    "            with Jobs_Completed_file.open(filename) as file:\n",
    "                #TextIOWrapper is used to ensure the program reads a string instead of a stream of bytes, which results in a TypeError.\n",
    "                #Readlines passes each line into a list object.\n",
    "                buffer = io.TextIOWrapper(file, encoding=\"utf-8\").readlines()\n",
    "                #master_file is appended with all elements from all files. This produces a list that can be quickly searched/\n",
    "                master_file.append(buffer)\n",
    "\n",
    "#This uses regex to recognize digits 'd' of length 4, then 2, then 2. they can be separated by hyphens.\n",
    "date_regex = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "\n",
    "#Now, for each of the 5 sublists of master_file, each list item created by .readlines() is read.\n",
    "for buffer in master_file:\n",
    "    for string in buffer:\n",
    "        #match is a buffer item we'll append to a master date_list.\n",
    "        match = date_regex.search(string)\n",
    "        if match:\n",
    "            date_list.append(match.group())\n",
    "\n",
    "\n",
    "\n",
    "#Now we'll iterate through the list of dates using if conditions to establish a range.\n",
    "\n",
    "#Creating boundaries here.\n",
    "start_date = '2018-08-15'\n",
    "end_date = '2018-09-15'\n",
    "\n",
    "dates_in_range = []\n",
    "\n",
    "for date in date_list:\n",
    "    if date >= start_date:\n",
    "        if date <= end_date:\n",
    "            dates_in_range.append(date)\n",
    "print(f\"The number of entries between {start_date} and {end_date} is {len(dates_in_range)}\")\n",
    "\n",
    "#To find the year in which the most jobs were created, I'll strip the year from all date_list entries and append it to a years_only list.\n",
    "#Then, we can just run statistics.mode\n",
    "# years_only = []\n",
    "# year = re.compile(r'\\d{4}')\n",
    "# for date in date_list:\n",
    "#     match = year.search(string)\n",
    "#     #The use of .group means that the list will only be appended with the string and not other information.\n",
    "#     years_only.append(match.group())\n",
    "\n",
    "print(f'The day with the most associated jobs is: {statistics.mode(date_list)}')\n",
    "\n",
    "#For the total time elapsed between first and last jobs, we'll use max and min on the date_list\n",
    "\n",
    "#We'll have to convert to a datetime object here so we can perform operations on the dates.\n",
    "\n",
    "first_job = datetime.strptime(min(date_list), '%Y-%m-%d')\n",
    "last_job = datetime.strptime(max(date_list), '%Y-%m-%d')\n",
    "time_delta = last_job - first_job\n",
    "#We could get rid of the time element with strftime, but it seems overkill here. 'string-from-time.'\n",
    "print(f\"The days elapsed between the first job and last job are {time_delta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of triangles is: 44\n",
      "Total area of all triangles is: 1022629.4450895642. \n",
      " The areas of each triangle in the mesh follow:\n",
      "[0.0, 0.0, 0.0, 2638.9353534853403, 5472.944843684953, 13085.550675119106, 9744.057557894803, 0.0, 106497.19095809023, 15631.535308557655, 145880.1784239923, 145880.1784239923, 106497.19095809023, 9459.949236665683, 9459.949236665685, 28294.53112314489, 3692.9550878294663, 28294.5311231449, 26323.460256115435, 3692.9550878294663, 45158.04214259463, 45158.04214259464, 26323.460256115435, 5472.944843684953, 5472.944843684953, 2638.9353534853403, 0.0, 9933.88744898081, 2638.9353534853412, 0.0, 6537.786042777389, 9933.887448980808, 7099.877958781198, 7099.877958781198, 3566.0235234441257, 13167.256416249083, 33228.97134803277, 11531.591827811746, 28377.47583342216, 27533.410225028416, 15783.804821429241, 11188.593735626715, 14246.033970931187, 29991.567939339788]\n"
     ]
    }
   ],
   "source": [
    "# Qn 5 (25 points)\n",
    "# Read the following (6_Part1.stl) triangular mesh file available in ASCII format. \n",
    "# For those of you aware of 3D printing, you will recognize this is as a .STL file. \n",
    "# For those who aren’t aware of what a .STL file is, please read up online on the format of a .STL ascii file. \n",
    "# An ASCII formatted .STL file can be opened in any text editor. \n",
    "# Every vertex of the triangle is preceeded by the word ‘vertex’ followed by the x, y and z coordinates. \n",
    "# Therefore, ONE Triangle should have 3 vertex entries. Typically, the units is not specified, \n",
    "# but you can assume it to be in millimeters. \n",
    "\n",
    "# Write functions that calculate the following: (20 points)\n",
    "# a.\tFind the total number of triangles listed in the file.\n",
    "# b.\tStore the coordinates of each triangle in a 3-tuple list_input containing N indices, where N is the total number of triangles.\n",
    "# c.\tlist_input the area of each triangle in the file. Compute the total surface area of all triangles listed in the file. Read up online on the formula to calculate the area of a triangle, given three vertices.\n",
    "# '''\n",
    "\n",
    "file = \"C:/Code/MFG598/Homework/6_Part1.stl\"\n",
    "vertex_count = 0\n",
    "\n",
    "#Using the counting function is going to be more lightweight than using file.readlines()\n",
    "    #...then iterating through the list of lines. We'll readlines later however.\n",
    "with open(file, \"r\") as stl_file:\n",
    "    file_data = stl_file.read()\n",
    "    vertex_count = file_data.count(\"vertex\")\n",
    "\n",
    "triangle_count = vertex_count/3\n",
    "\n",
    "print(f\"The number of triangles is: {int(triangle_count)}\")\n",
    "\n",
    "#Now we're using readlines and we'll use 'vertex' as a pointer to access just the tuple of values after it.\n",
    "with open(file, \"r\") as file:\n",
    "    file_data = file.readlines()\n",
    "\n",
    "triangles = []\n",
    "for line in file_data:\n",
    "    if 'vertex' in line:\n",
    "        coordinates = tuple([float(x) for x in line.strip().split()[1:]])\n",
    "        triangles.append(coordinates)\n",
    "\n",
    "#Now find the total area of all triangles, and also the area of each triangle.\n",
    "#I'm not sure if the question wants me to append this to list_input\n",
    "\n",
    "area_list = []\n",
    "\n",
    "\n",
    "tri = [triangles[i:i+3] for i in range(0, len(triangles), 3)]\n",
    "\n",
    "#Going to assume that the triangle format is Ax, Ay, Az, Bx, By, Bz...\n",
    "#Iterate through each grouping of vertices and then do the math for volume.\n",
    "def triangle_volume(tri):\n",
    "    x1, y1, z1 = tri[0]\n",
    "    x2, y2, z2 = tri[1]\n",
    "    x3, y3, z3 = tri[2]\n",
    "    return abs(x1*y2*z3 + x2*y3*z1 + x3*y1*z2 - x1*y3*z2 - x2*y1*z3 - x3*y2*z1) / 6\n",
    "\n",
    "volumes = [triangle_volume(triangle) for triangle in tri]\n",
    "print(f\"Total area of all triangles is: {sum(volumes)}. \\n The areas of each triangle in the mesh follow:\")\n",
    "print(volumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
