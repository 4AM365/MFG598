{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A cleaning services company compiled the following data related to the annual profit of the firm to its\n",
    "annual Facebook advertising campaign (measured in thousands) as shown in the table below\n",
    "\n",
    "| Advertising Expenditure | Profit |\n",
    "|------------------------|--------|\n",
    "| 12                     | 60     |\n",
    "| 14                     | 70     |\n",
    "| 17                     | 90     |\n",
    "| 21                     | 100    |\n",
    "| 26                     | 100    |\n",
    "| 30                     | 120    |\n",
    "\n",
    "a) Find the best least squares fit to the data in the form of a straight line given by y = mx + c by\n",
    "writing a numpy program.\n",
    "\n",
    "b) Plot the points and least square fit line using matplotlib.\n",
    "\n",
    "c) Calculate the profit if the company allocates in its next FB campaign with a 50,000 budget allocation. Report the value in $ currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Cannot just import matplot lib here. Need pyplot.\n",
    "import matplotlib.pyplot as plot\n",
    "#best least squares implies the use of NumPy polyfit\n",
    "\n",
    "#Let's start by creating arrays that represent the table.\n",
    "adv_exp = np.array([12, 14, 17, 21, 26, 30])\n",
    "profit = np.array([60,70,90,100,100,120])\n",
    "\n",
    "# A best-squares fit is achieved with a degree. We will arbitrarily assume a degree of 3.as_integer_ratio\n",
    "\n",
    "coefficients = np.polyfit(adv_exp, profit, deg = 3)\n",
    "\n",
    "x = np.linspace(0,30,100)\n",
    "\n",
    "y_fit = np.polyval(coefficients, x)\n",
    "\n",
    "#Creating scatter plot with expense as x axis and profit as y. \n",
    "    #Can include a third term label = 'xyz' if desired\n",
    "plot.scatter(adv_exp, profit)\n",
    "#This overlays the 'line of best fit'.\n",
    "plot.plot(x, y_fit)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Using code, open and read the contents of the files contained with the “bunchofJSONS.zip”\n",
    "file. For each file read, enter the contents of the JSON file into a Pandas Dataframe. The value\n",
    "of the ‘volume’ key in each of the JSON file is expressed in cubic mm. Update each value in\n",
    "the dataframe to convert the value into cubic inches (using the .apply() or .map() method).\n",
    "Calculate the total volume of all the objects in cubic inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Open the .zip and scrape a list of all files with the .namelist() function:\n",
    "with zipfile.ZipFile('bunchofJsons.zip', 'r') as bunch_of_jsons:\n",
    "    #This function is specific to zipfile.\n",
    "    file_list = bunch_of_jsons.namelist()\n",
    "#Verify that our file list is working:\n",
    "# print(file_list[:3])\n",
    "\n",
    "step_one_table_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    with zipfile.ZipFile('bunchofJsons.zip', 'r') as bunch_of_jsons:\n",
    "        with bunch_of_jsons.open(file) as open_file:\n",
    "            #I don't need to nest commands here because json.load serves to append data to 'data'.\n",
    "            data = json.load(open_file)\n",
    "\n",
    "    # print(file, data)\n",
    "\n",
    "    #read through each dictionary key piecemeal and re-write it as a converted value\n",
    "    #Needed to manually open a .json to find the key here.\n",
    "    converted_volumes = data['compProperties'][\"volume\"] / 16387.064\n",
    "\n",
    "    #appending converted values to data here\n",
    "    data['converted_volumes'] = converted_volumes\n",
    "\n",
    "    new_data_frame = pd.DataFrame(data, index = [0])\n",
    "    step_one_table_list.append(new_data_frame)\n",
    "    \n",
    "master_dataframe = pd.concat(step_one_table_list, ignore_index = True)\n",
    "\n",
    "total_vol = master_dataframe['converted_volumes'].sum()\n",
    "\n",
    "print(f\"Total volume is: {total_vol}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read the ‘sales.csv’ file into a pandas dataframe. Split the Location column into two additional\n",
    "columns of City and State. The new dataframe should retain the original column but with two\n",
    "additional columns added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "with open('sales.csv','r'):\n",
    "    sales_dataframe = pd.read_csv('sales.csv',',')\n",
    "\n",
    "#Preliminary data analysis:\n",
    "print(sales_dataframe.head())\n",
    "\n",
    "#Python data isn't 'sequential' and can be thought of as happening 'all at once.'\n",
    "#Therefore, we need to break the link between the new dataframe and old one - they can't simply be equal at some point.\n",
    "#.copy() accomplishes this.\n",
    "new_sales_dataframe = sales_dataframe.copy()\n",
    "\n",
    "#Here, we're simply appending values from old to new, but splitting them.\n",
    "#expand = True means that when the value is split, it isn't sent as a two-item list to a single column.\n",
    "#Instead, each item gets a column.\n",
    "new_sales_dataframe[['City', 'State']] = sales_dataframe['Location'].str.split(', ', expand = True)\n",
    "\n",
    "# Printing data to check.\n",
    "print(new_sales_dataframe.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. With respect to the same dataframe created above from sales.csv, answer the following\n",
    "questions:\n",
    "a. Which Item‐Type was sold the most?\n",
    "b. Which Item‐Type generated the most revenue?\n",
    "c. For items that were sold below 1000 units, which item‐type generated the most\n",
    "total‐profit?\n",
    "d. What item‐types were sold in the State – ‘AZ’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, which item-type was sold most?\n",
    "\n",
    "#.sum() and .nlargest(1) are chained so perform two operations in one line.\n",
    "#.sum() serves to sum the sales of each item.\n",
    "#.nlargest produces the largest 'n' (number) and only the largest (1). We could find the 3 largest, or 4, etc.\n",
    "most_sold_item_type = sales_dataframe.groupby('Item Type')['Units Sold'].sum().nlargest(1)\n",
    "print(f\"The item type that was sold the most is {most_sold_item_type.index[0]} with {most_sold_item_type.values[0]} units sold.\")\n",
    "\n",
    "#b) Which item-type generated the most revenue?\n",
    "\n",
    "#Same code as above.\n",
    "highest_revenue_item_type = sales_dataframe.groupby('Item Type')['Total Revenue'].sum().nlargest(1)\n",
    "print(f\"The item type that generated the most revenue is {highest_revenue_item_type.index[0]} with a total revenue of ${highest_revenue_item_type.values[0]:,.2f}.\")\n",
    "\n",
    "#c) Which items generated the most profit with a unit quantity < 1000 ?\n",
    "\n",
    "#The line below can be read as 'the new dataframe is equal to the old dataframe, such that the old dataframe entry is less than 1000'\n",
    "sold_below_1000 = sales_dataframe[sales_dataframe['Units Sold'] < 1000]\n",
    "most_profitable_below_1000 = sold_below_1000.groupby('Item Type')['Total Profit'].sum().nlargest(1)\n",
    "print(f\"For items sold below 1000 units, the most profitable item type is {most_profitable_below_1000.index[0]} with a total profit of ${most_profitable_below_1000.values[0]:,.2f}.\")\n",
    "\n",
    "#d) Which items were sold in AZ?\n",
    "items_sold_in_az = sales_dataframe.loc[new_sales_dataframe['State'] == 'AZ', 'Item Type'].unique()\n",
    "print(f\"The following item types were sold in Arizona: {', '.join(items_sold_in_az)}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Given the following table, write code that perform the following set of steps.\n",
    "\n",
    "| Column 1 | Column 2 | Column 3 | Column 4 |\n",
    "|----------|----------|----------|----------|\n",
    "| A        | B        | C        | D        |\n",
    "| VINE     | THE WONDER | PIZZA    |          |\n",
    "| BEAUTY   | SIRE     | NUN      | NONE     |\n",
    "| COOPERATION | EAST     | NOBODY OF |          |\n",
    "| NOON     | OOLONG   | THE UNIVERSE |       |\n",
    "| AIRPLANE | MY       | SUBTERFUGE DEED |    |\n",
    "| NEVER    | WORLD    | RESIN    | DONOR    |\n",
    "| TOO      | TWO      | CLOUD    | EVEN     |\n",
    "| LIES     | SERENDIPITY | PRIZE   | SWIFT    |\n",
    "| RAPID    | OBOE     | ANYBODY IN |        |\n",
    "| THE MULTITUDE | SPEEDY | MATHEMATICAL |       |\n",
    "| PIZZAZZ  | SURE     | DIVERSITY | RUIN     |\n",
    "| RAINBOW  | WARE     | WEAR     | MOON     |\n",
    "| SOMEONE OF | STAR    | ABBA     |          |\n",
    "| KAYAK    | MONOPOLY | ITS      | EYE      |\n",
    "\n",
    "The above table is stored as a ‘word‐table.csv’ file to be read into a dataframe. The sets of operations to be performed on the above table is as follows:(note, that these operations must operate in the order displayed below. That is the result of operation 1 feeds into operaton 2, which then feeds into operation 3).\n",
    "\n",
    "Read the table into a Pandas Dataframe\n",
    "Perform the following operations:\n",
    "Replace words that appear to the immediate right of the word ‘THE’ with the value ‘NONE’\n",
    "\n",
    "In columns B and D, replace all words that contain two or more O’s with the value ‘NONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A       B           C         D\n",
      "0         VINE     THE      WONDER     PIZZA\n",
      "1       BEAUTY    SIRE         NUN      NONE\n",
      "2  COOPERATION    EAST      NOBODY        OF\n",
      "3         NOON  OOLONG         THE  UNIVERSE\n",
      "4     AIRPLANE      MY  SUBTERFUGE      DEED\n",
      "\n",
      "             A       B           C      D\n",
      "0         VINE     THE        NONE  PIZZA\n",
      "1       BEAUTY    SIRE         NUN   NONE\n",
      "2  COOPERATION    EAST      NOBODY     OF\n",
      "3         NOON  OOLONG         THE   NONE\n",
      "4     AIRPLANE      MY  SUBTERFUGE   DEED\n",
      "\n",
      "           A            B           C             D\n",
      "0       VINE          THE        NONE         PIZZA\n",
      "1     BEAUTY         SIRE         NUN          NONE\n",
      "2       NONE         EAST      NOBODY            OF\n",
      "3       NONE         NONE         THE          NONE\n",
      "4   AIRPLANE           MY  SUBTERFUGE          DEED\n",
      "5      NEVER        WORLD       RESIN         DONOR\n",
      "6       NONE          TWO       CLOUD          EVEN\n",
      "7       LIES  SERENDIPITY       PRIZE         SWIFT\n",
      "8      RAPID         OBOE     ANYBODY            IN\n",
      "9        THE         NONE      SPEEDY  MATHEMATICAL\n",
      "10   PIZZAZZ         SURE   DIVERSITY          RUIN\n",
      "11   RAINBOW         WARE        WEAR          NONE\n",
      "12   SOMEONE           OF        STAR          ABBA\n",
      "13     KAYAK     MONOPOLY         ITS           EYE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Craig UHES\\AppData\\Local\\Temp\\ipykernel_7548\\3601367866.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  step_one_table[mask] = step_one_table[mask].apply(lambda x: x.str.replace(r'\\b\\w*OO\\w*\\b', 'NONE'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "#Place the csv into buffer here...\n",
    "control_copy_table = pd.read_csv('word-table.csv')\n",
    "\n",
    "step_one_table = pd.read_csv('word-table.csv')\n",
    "\n",
    "print(f\"{control_copy_table.head()}\\n\")\n",
    "\n",
    "#First, replace words that appear to the right of THE with the value 'NONE'\n",
    "\n",
    "#Need to learn a better approach here instead of using the column names. Perhaps I could substitute the column name\n",
    "#in each command for a pointer to the column name which references the index.\n",
    "for i, row in step_one_table.iterrows():\n",
    "    if 'THE' in row['A']:\n",
    "        step_one_table.at[i, 'B'] = 'NONE'\n",
    "\n",
    "for i, row in step_one_table.iterrows():\n",
    "    if 'THE' in row['B']:\n",
    "        step_one_table.at[i, 'C'] = 'NONE'\n",
    "\n",
    "for i, row in step_one_table.iterrows():\n",
    "    if 'THE' in row['C']:\n",
    "        step_one_table.at[i, 'D'] = 'NONE'\n",
    "\n",
    "print(f\"{step_one_table.head()}\\n\")\n",
    "\n",
    "#Then, replace all words in column B and D that contain two or more Os with 'NONE'\n",
    "        #This one didn't work. Later on, I realized that 'O'*2 = 'OO'. This won't help for 'MONOPOLY.'\n",
    "            # step_one_table[['B', 'D']] = step_one_table[['B', 'D']].applymap(lambda x: x if 'O'*2 not in x else 'NONE')\n",
    "\n",
    "#Figured we could create a mask with the locations of each cell, then use that to replace with NONE.\n",
    "mask = step_one_table.apply(lambda x: x.str.count('O')).ge(2).any(axis=1)\n",
    "\n",
    "# #This method gets me closer, but I end up using lambda to evaluate each row and changing everything to NONE.\n",
    "# step_one_table.loc[mask] = 'NONE'\n",
    "\n",
    "step_one_table[mask] = step_one_table[mask].apply(lambda x: x.str.replace(r'\\b\\w*OO\\w*\\b', 'NONE'))\n",
    "\n",
    "\n",
    "print(step_one_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
